export const ragQuestions = [
    { question: "What problem does RAG (Retrieval-Augmented Generation) fundamentally solve?", answer: "LLMs have frozen knowledge cutoff dates (e.g., they know nothing past 2023) and they heavily Hallucinate facts. Fine-tuning a massive model weekly just to teach it new corporate policies is financially impossible. RAG fixes this by acting as an 'open-book test'. We search an external database for the answer, inject the exact paragraph into the prompt, and tell the LLM: <em>'Answer the user ONLY using this paragraph.'</em>" },
    { question: "If an LLM has a Massive 1-Million Token Context Window, why use RAG instead of just pasting all PDFs into the prompt every time?", answer: "Cost and Latency. Pushing 1 million tokens through a giant neural network like GPT-4 costs dollars <strong>per query</strong> and takes massive compute time (seconds/minutes), plus it heavily suffers from the 'Lost in the Middle' problem (ignoring data in the center of the prompt). With RAG, you pay a fraction of a cent to search millions of documents instantly via vectors, and only feed the top 3 best paragraphs into the LLM." },
    { question: "What is an Embedding Vector?", answer: "A massive list of numbers (coordinates) generated by an Embedding Model (like OpenAI's text-embedding-ada). It reads a sentence and condenses its entire semantic, conceptual <em>meaning</em> into thousands of dimensions. In this math space, the concept of 'King' and 'Queen' sit extremely close to each other, while 'Potato' is millions of miles away." },
    { question: "Explain Cosine Similarity in the context of Vector Databases.", answer: "Once you have text converted to Vectors, you need to search them. Euclidean Distance measures standard straight-line metric distance. However, in text, one document might be 5 pages long, and the user's question is 5 words long. Their raw Euclidean distance is terrible. <strong>Cosine Similarity</strong> measures the <em>angle</em> between the vectors, ignoring their sheer length (magnitude). If the angle is incredibly small, they point in the exact same conceptual direction, meaning they are a semantic match." },
    { question: "What is a 'Chunking Strategy' in document ingestion?", answer: "You cannot embed an entire 500-page book as a single vector; the meaning gets washed out. You must split the book into chunks. A bad strategy is splitting strictly by character limits (e.g., exactly 500 characters), which randomly slices sentences in half. A good strategy relies on structural boundaries (splitting by markdown headers `##` or paragraphs) and using 'Chunk Overlap' (duplicating the last 50 words of Chunk 1 into the start of Chunk 2) to prevent context loss." },
    { question: "Explain 'Hierarchical Chunking' (Parent-Child Chunking).", answer: "You chop a massive document into huge 'Parent' chunks (maybe an entire page each). You then chop those pages into tiny 'Child' chunks (sentences). You calculate embeddings only on the Child sentences to get incredibly sharp, highly accurate search hits. However, when you give it to the LLM, you retrieve the <em>entire Parent chunk</em>. This gives the LLM massive surrounding context (the entire page) built around the incredibly precise sentence hit." },
    { question: "What is the 'Lost in the Middle' problem, and how does RAG Re-Ranking solve it?", answer: "Research proves LLMs heavily 'weigh' the first paragraph and the last paragraph of their prompt window, severely ignoring facts jammed into the middle. Re-Ranking is an advanced pipeline step. Vector Search retrieves the top 20 hits. We then place the absolute best hit at the very top of the prompt, the second best hit at the absolute bottom of the prompt, and hide the weaker hits in the deadly middle zone to guarantee high accuracy." },
    { question: "What is Hybrid Search (Semantic + Keyword)?", answer: "Standard vector search matches meaning: 'How do I fix the engine?' hits 'Automotive repair manual'. But vector math completely fails at incredibly specific strings, like matching serial number 'RX-8840-X'. Hybrid search simultaneously runs an AI Vector Search alongside an old-school Sparse Keyword Search (like BM25/Elasticsearch). It then mathematically combines the scores (Reciprocal Rank Fusion) to get the best of both worlds." },
    { question: "What is a Cross-Encoder Re-Ranker model?", answer: "Basic vector search (Bi-Encoder) calculates the user query vector independently from the document vector and compares them. It is very fast, but contextually weak. A Cross-Encoder takes both the 'User Query' and 'Candidate Document' and forces them through a massive neural network together at the exact same time, capturing hyper-complex relations. It is brutally slow, so we only use it at the very end to perfectly re-sort the final Top 10 documents." },
    { question: "What is 'Query Rewriting' (or Query Expansion/HyDE)?", answer: "Users write terrible queries ('Why is it broken?'). RAG fails instantly. In an advanced pipeline, before searching the database, we secretly pass the bad query to a massive LLM. We ask: <em>'Rewrite this query based on chat history to be extremely precise'</em> or <em>'Generate a fake exact answer to this question' (HyDE)</em>. We then use that perfectly generated hallucination to search the vector database, drastically improving retrieval." },
    { question: "What is a Graph RAG approach?", answer: "Instead of purely relying on flat text paragraphs (Chunks), the pipeline uses an LLM to extract rigorous 'Knowledge Graphs' (Entities and Relationships) from text during ingestion. Node: 'Elon Musk' -> Edge: 'purchased' -> Node: 'Twitter'. When a query hits, it navigates this complex network of interlinked nodes to provide highly complex, multi-hop answers impossible in standard vector generation." },
    { question: "How does RAG actually stop a hallucination during the generation step?", answer: "The magic is in the System Prompt constraints. <code>'You are a support bot. ONLY use the retrieved paragraphs below to answer. If the answer is not in the text, you MUST reply \"I don't know.\" Do not use prior knowledge.'</code> By strongly grounding the autoregressive flow entirely in the context window, the model is mathematically pushed away from its pre-training weights." },
    { question: "What is Metadata Filtering in a Vector Database?", answer: "To speed up searches and enforce security constraints. When embedding a document, you attach hard JSON metadata (e.g., <code>{department: 'HR', clearance: 'Level 2'}</code>). If an intern queries the system, before running the expensive math Vector Search, the database applies a hard filter to completely exclude all 'Level 5' documents, providing massive security and speed." },
    { question: "Explain the concept of 'Routing' in advanced RAG frameworks.", answer: "Not every query requires heavy vector retrieval. If the user asks 'Hello', RAG is useless. A Router is a tiny classification model (or LLM) sitting at the front door. Query: 'Hello' -> routes directly to Chat. Query: 'Sales figures 2023' -> routes to SQL Agent. Query: 'Employee Handbook' -> routes to Vector RAG pipeline. This prevents wasting extremely expensive API calls." },
    { question: "What is the typical tech stack for a basic RAG application?", answer: "1. <strong>LLM:</strong> GPT-4 or Claude (for synthesizing the final answer).\n2. <strong>Embedding Model:</strong> text-embedding-ada or BAAI/bge (for converting text to numbers).\n3. <strong>Vector Database:</strong> Pinecone, Milvus, ChromaDB, or pgvector (for storing and searching thousands of dimensions).\n4. <strong>Framework:</strong> LangChain or LlamaIndex (glue code to tie chunks, queries, and LLM calls together)." },
    { question: "Why is taking chunking boundaries seriously critical?", answer: "Imagine an instruction manual: <code>Line 1: DO NOT PRESS THE BUTTON. Line 2: If you press it, the factory explodes.</code> If a naive chunking algorithm blindly splits the file exactly at 50 characters, Chunk A might be: <code>DO NOT PRESS THE BUTTON. If you pre</code> and Chunk B: <code>ss it, the factory explodes.</code> If a user searches 'What causes an explosion', they retrieve Chunk B solely, which has no context, resulting in a hallucinated or useless LLM response." },
    { question: "What is the 'Self-Reflective RAG' methodology?", answer: "Instead of just retrieving and generating blindly, we add a loop. The LLM generates the answer, then we run a second LLM to grade it: 'Did this answer actually use the context? Does it perfectly address the user? Is it hallucinating?' If the grader fails the text, the loop forces the system to either rewrite the original user query and search the database again, or rewrite the answer." },
    { question: "Can you fine-tune an Embedding Model?", answer: "Yes, and it provides incredible boosts for niche industries. If you work in highly specific legal tech, standard OpenAI embeddings might map 'Tort' near 'Cake'. By manually creating a massive file of pairs showing (Legal Query A -> Highly relevant Legal Document B), you can computationally adjust the vector space of open source models like BGE to drag relevant domain concepts physically closer together on the multi-dimensional map." },
    { question: "How does sliding window chunking (overlap) fix contextual loss?", answer: "When slicing a large text into chunks, you don't cut cleanly at the sentence dot. Chunk 1 goes from sentences 1-10. Chunk 2 starts at sentence 8 and goes to 18. This 2-sentence overlap ensures that 'dangling pronouns' or ideas split between chunks still exist fully intact in at least one retrieved sector, maintaining the complete conceptual thread." },
    { question: "What happens if the retrieved documents wildly contradict each other?", answer: "This is a classic 'Conflicting Context' issue. E.g., V1 of a manual says 'Press Blue', V2 says 'Press Red'. If RAG grabs both, the Generator LLM crashes or guesses. Solution: Rigorously enforce Metadata tagging during ingestion (stamping creation dates) and always sort Vector hits by timestamp metadata descending before feeding to the LLM to prioritize truth." },
    { question: "Why is 'Reciprocal Rank Fusion' used in Hybrid Search?", answer: "Dense Vector Search ranks documents based on decimal math (e.g., 0.88 similarity). Sparse Keyword Search (BM25) ranks on arbitrary unbounded integers (e.g., score 45.2). To combine these radically different scoring scales, we completely ignore the scores. We rank them solely by position (Rank 1, Rank 2...). RRF applies a formula <code>1 / (k + Rank)</code>. If Document A is Rank #1 in Vector and Rank #30 in Keyword, it gets a combined mathematical score valuing high presence across multiple distinct algorithms." }
];

export const agentsQuestions = [
    { question: "What fundamentally distinguishes an AI 'Agent' from a standard RAG or Chatbot application?", answer: "A chatbot replies with text. A RAG application retrieves text and replies with text. An <strong>Agent</strong> has the autonomous capability to execute code (Tools) to affect the external environment. Given a complex goal, it can independently reason, write code, query dynamic APIs, read the failure response, rewrite its code, and loop autonomously until the goal is complete entirely without human intervention." },
    { question: "What is the ReAct architecture (Reasoning and Acting)?", answer: "It is the foundational blueprint for preventing agents from looping blindly. It forces the LLM to obey a strict output format: <strong>Thought -> Action -> Observation</strong>. \n\n1. It must explicitly write its <em>Thought</em> process ('I see the error is 404, I must change the URL').\n2. It outputs an execution <em>Action</em> ('[TOOL: WebBrowser URL: ...]').\n3. The Python framework executes it and injects the text <em>Observation</em>. This forced logic loop drastically improves completion reliability." },
    { question: "How does a Large Language Model actually execute a Tool or API?", answer: "Through <strong>Function Calling</strong> schema. The Developer injects a massive JSON schema into the System Prompt describing the available tools (e.g., Name: Calculator, Args: Num1, Num2). The LLM does not run code. It simply generates a highly structured JSON string (e.g., `{'tool': 'calc', 'num1': 5, 'num2': 10}`). Our external Python program intercepts this JSON, runs the real Python math, and feeds the string '50' back into the chat history." },
    { question: "What happens if an Agent encounters an error running a tool? Will it crash?", answer: "A well-designed agent handles exceptions. When the Python code hits a traceback (e.g., 'API Auth Error'), we do not crash the script. We physically convert that red error traceback into a text string and feed it back to the LLM as the 'Observation'. A capable LLM will read the error, write a new <em>Thought</em> ('Ah, I forgot to include the API key header'), format a new tool JSON, and retry successfully." },
    { question: "What is the difference between a Single Agent workflow and a Multi-Agent system?", answer: "Single Agents handle straight-line tasks easily. However, a single LLM evaluating its own work suffers massive confirmation bias. <strong>Multi-Agent systems (like CrewAI or AutoGen)</strong> separate tasks. A 'Coder Agent' writes code. A 'QA Tester Agent' attacks the code. A 'Manager Agent' orchestrates. This adversarial setup mimics human enterprise pipelines and results in vastly superior, drastically more reliable code generation." },
    { question: "Explain the concept of 'Routing' vs 'Autonomy' in Agent design.", answer: "In massive enterprise systems, total autonomy (letting an LLM do whatever it wants in a loop) is terrifying and extremely expensive. <strong>Routing</strong> forces strict guardrails: A supervisor LLM analyzes the user prompt and routes it deterministically to specialized, highly restricted tool-chains (State Machines). This limits true 'open-ended autonomy' but guarantees business-safe stability." },
    { question: "How does an Agent maintain 'Memory' across a session?", answer: "Memory is just chat history. \n1. <strong>Short-term memory:</strong> Simply passing the entire sequence of previous Thoughts, Actions, and Observations back into the prompt window.\n2. <strong>Long-term memory:</strong> When the prompt gets too large, we must summarize the history. Or, we dynamically insert and retrieve past user preferences from a Vector Database (RAG) directly into the agent's prompt on boot." },
    { question: "What is 'Plan and Solve' prompting compared to ReAct?", answer: "ReAct acts immediately on its first thought, often trapping itself in rabbit holes. 'Plan and Solve' forces the Agent to freeze. Before using a single tool, it MUST output a 10-step bulleted plan for the entire objective. It then creates a checklist. As it executes loop by loop, it crosses items off the checklist. This drastically prevents wandering out of scope on complex mega-tasks." },
    { question: "What is the critical danger of connecting LLM Agents to SQL Databases?", answer: "Agents generate and execute code autonomously. If you give an Agent unrestricted execute access to a production SQL database and a user maliciously prompts: <em>'Please delete all table rows to clear some space'</em>, the Agent will happily execute `DROP TABLE users;`. Agents executing code must be isolated in strict read-only Sandboxes (Docker/WASM) with zero destructive permissions." },
    { question: "What is an LLM Compiler/Supervisor pattern?", answer: "In a Multi-Agent setup with 20 distinct agents, you cannot let them all talk simultaneously. A Supervisor LLM looks at the goal, selects exactly 1 Worker Agent, passes it parameters, waits for it to finish, reviews the output, and then routes to the next Worker. It acts as the ultimate CPU orchestrator, ensuring total directional control over the swarm." },
    { question: "What is the primary cause of an Agent getting caught in an 'Infinite Tool Loop'?", answer: "Usually, the LLM is not smart enough (e.g., trying to use Llama-8B for complex agent logic). Or, the 'Observation' returned by the tool is too vague ('Error 500'). The model cannot logically deduce the <em>reason</em> for the failure, so it panics and repeats the exact same tool call identically over and over. Fixing this requires 1) smarter models (GPT-4) and 2) extremely verbose, descriptive tool error messages." },
    { question: "How does the 'Code Interpreter' architecture function?", answer: "OpenAI's Advanced Data Analysis is the gold standard. Instead of writing 20 specific API tools (Calculator, Chart Maker, etc.), they give the LLM exactly ONE tool: A fully functioning hidden Python Jupyter environment. The LLM writes pure Python to solve any problem (data science, math, image cropping), sends the script to the sandbox, receives the console output/images back, and displays it." },
    { question: "What is the difference between a Task-Driven Agent and a Persona-Driven Agent?", answer: "<strong>Task:</strong> You are a SQL extractor. Your only goal is to turn English to SQL and fetch data instantly. Highly restricted.\n<strong>Persona:</strong> (e.g., AutoGen avatars or AI Companions). They are heavily prompted to adopt complex personalities, emotions, and specific domain knowledge biases. They communicate conversationally, heavily used in gaming or creative writing swarms." },
    { question: "Why is 'Function Calling' vastly safer than 'Regex Parsing' for tools?", answer: "Before Function Calling APIs, developers begged the LLM to write output perfectly like `Action: [Search] Args: [Dog]`. Developers then used fragile Regex scripts to hunt for that string. If the LLM hallucinated an extra bracket `[Search]]`, the code crashed. Function Calling forces the model at the API inference level to output perfect JSON structures matching a strict schema, eliminating parsing crashes entirely." },
    { question: "How does an Agent recognize it has 'Finished' a task?", answer: "By providing a specific, final terminal tool. Often called something like `Final_Answer_Tool`. The prompt instructs: <em>'When you have confidently gathered all data and satisfied the prompt, you MUST call the Final_Answer tool with the summary string to exit the loop.'</em> If it calls this, the Python loop breaks and returns the result to the user." },
    { question: "What is 'Human-in-the-Loop' (HITL) architecture?", answer: "Crucial for enterprise automation. The agent works autonomously compiling data, writing an email, and attaching files. However, before the actual <code>Send_Email_Tool</code> is allowed to execute, the framework violently pauses the script. A physical prompt pops up on a human manager's screen. Only if the human clicks 'Approve' does the LLM receive the authorization token to execute the final destructive/public action." },
    { question: "What is the 'Context Window Overflow' problem in Agents?", answer: "Agents run in loops. Loop 1: Web Scrape (returns 10,000 words). Loop 2: Read PDF (returns 20,000 words). Because the prompt MUST include all past history to maintain memory, by Loop 5, the prompt exceeds 128k tokens and the model crashes violently with an Out-of-Memory API error. Agents require aggressive automatic summarization of past steps or chunk-truncation to survive long sessions." },
    { question: "Can Open Source models (like Mistral or Llama) function as reliable Agents?", answer: "Yes, but it requires highly specific fine-tuning. Base open-source models are notoriously bad at outputting perfect JSON or resisting hallucinations over multiple loops. However, models like specifically fine-tuned `Hermes`, `Llama-3-Instruct`, or `Gorilla` excel at function calling. For elite, zero-shot 10-step complex agent routing, massive proprietary models (Claude 3.5 Sonnet / GPT-4o) still dominate." },
    { question: "What are 'Guardrails' in Agent engineering?", answer: "A secondary, microscopic safety model sitting entirely outside the main Agent loop. As the Agent generates its action (e.g., `Write files to disk`), before executing, the Guardrail model scans the JSON payload against blacklists or safety paradigms. If it detects malicious injection or unapproved APIs, it alters or kills the action, providing extreme defense against Prompt Injection hacks." },
    { question: "In a CrewAI hierarchy, what makes an agent 'Delegated' vs 'Autonomous'?", answer: "An autonomous agent operates alone. A Delegated agent explicitly has the framework capability to 'sub-contract' its work. If the Executive Agent realizes the task involves complex math, it can transparently spawn a subordinate 'Math Agent', wait for the result, taking credit for it, entirely shielding the complexity from the root orchestrator." },
    { question: "Summarize the major difference between traditional 'Coding' and agentic 'Prompt Engineering'.", answer: "Traditional coding is deterministic. `if x > 5: do Y`. You handle all edge cases explicitly. \nAgent engineering is stochastic and probabilisitic. You cannot code every edge case of human language or webpage failure. Instead, you write massive, dense architectural prompts outlining general principles, fallbacks, and behavioral psychology, relying on the immense emergent reasoning of the engine to figure out the code logic dynamically in real time." }
];

export const algorithmsQuestions = [
    { question: "What is the fundamental difference between an Uninformed (Blind) search and an Informed (Heuristic) search?", answer: "Uninformed search algorithms (like BFS, DFS, Dijkstra's) have zero knowledge about where the goal physically is on the map. They expand blindly based entirely on the cost of the path taken so far. \nInformed search algorithms (like greedy search or A*) use a <strong>Heuristic</strong>—an educated mathematical guess (like a straight-line GPS coordinate check) to vigorously bias the search in the direction of the target, massively speeding up computation." },
    { question: "Explain Depth-First Search (DFS) vs Breadth-First Search (BFS).", answer: "<strong>BFS</strong> explores equally in all directions, layer by layer like a ripple in a pond. It guarantees the absolute shortest path on an unweighted graph, but uses massive amounts of RAM to store the frontier. \n<strong>DFS</strong> plunges aggressively down a single path as far as possible until it hits a dead-end, then backtracks. It is terrible at finding the 'shortest' path, but requires almost zero memory. Great for simple maze solving." },
    { question: "How does Dijkstra's Algorithm improve upon BFS?", answer: "BFS assumes every step (edge) has a cost of '1'. It fails miserably on weighted graphs (e.g., driving slowly through a muddy road vs fast on a highway). Dijkstra keeps a priority queue tracking the <em>lowest total accumulated cost</em> from the start node. It systematically expands the 'cheapest' node globally available, guaranteeing the absolute cheapest path on any graph containing positive weights." },
    { question: "Why does Dijkstra's Algorithm fail if a graph contains negative weight edges?", answer: "Dijkstra locks in the shortest path to a node permanently the instant it visits it, based on the greedy assumption that 'adding more edges will only ever <em>increase</em> the cost'. A negative edge (e.g., a magic portal that subtracts 50 minutes of driving time) dynamically lowers the cost of previously visited routes. Dijkstra is blind to this. You must use the slower Bellman-Ford algorithm for negative weights." },
    { question: "What is A* (A-Star) Search, and what is its fundamental mathematical equation?", answer: "The king of pathfinding algorithms (powers all video games and GPS). It mathematically combines Dijkstra's guaranteed accuracy with the speed of greedy guessing. \nThe formula evaluates every node using: <code>f(n) = g(n) + h(n)</code>.\n- <strong>g(n):</strong> The perfect, exact accumulated cost from the start to current node (Dijkstra).\n- <strong>h(n):</strong> The <em>Heuristic</em> guess of the remaining distance to the goal.\nA* expands the node with the lowest total expected <code>f(n)</code> cost." },
    { question: "What does it mean for a Heuristic to be 'Admissible' in A* Search?", answer: "If a heuristic is Admissible, it <strong>never overestimates</strong> the true cost to reach the goal. (e.g., estimating 10 miles when the true road distance is 15 miles). If the heuristic is overly optimistic, A* is mathematically guaranteed to find the perfect shortest path. If it ever overestimates (guessing 20 miles when it's only 15), A* might skip a perfect shortcut, returning a flawed, sub-optimal route." },
    { question: "What does it mean for a Heuristic to be 'Consistent' (or Monotonic)?", answer: "A stricter version of Admissible. It adheres to the triangle inequality. Simply put, exploring from Node A to Node B should never magically result in an <code>f(n)</code> score that somehow jumps backwards and becomes cheaper than Node A. If a heuristic is Consistent, A* never has to painfully re-evaluate nodes it has already closed and moved past, making it brutally fast." },
    { question: "Explain the Manhattan Distance vs Euclidean Distance heuristic.", answer: "Both are heuristics used in A* for grid maps.\n- <strong>Euclidean:</strong> Straight-line 'as the crow flies' distance (Pythagorean theorem). Used if movement in absolutely any angular direction is freely allowed.\n- <strong>Manhattan:</strong> Restricts movement to strict vertical and horizontal steps (like city blocks). Calculates absolute vertical plus absolute horizontal difference. Far more accurate for strict grid-based mazes." },
    { question: "What is the Minimax algorithm, and where is it primarily used?", answer: "An adversarial search algorithm used in 2-player turn-based, zero-sum games with perfect information (Tic-Tac-Toe, Checkers, Chess). It simulates millions of future board states down to the end of the game. It assumes <strong>You (Max)</strong> will always make the move that maximizes your score, and the <strong>Opponent (Min)</strong> will flawlessly make the move that minimizes your score. It selects the current move that has the best 'worst-case scenario'." },
    { question: "Why is the raw Minimax algorithm completely useless for the game of Chess?", answer: "The 'Branching Factor' of Chess is immense (average ~35 moves per turn). To look merely 10 turns ahead requires evaluating <code>35^10</code> (quadrillions) of board states. The universe would end before a standard computer evaluated every single raw node down to the endgame. Minimax must be drastically optimized using Alpha-Beta Pruning and limited depth evaluation functions." },
    { question: "What is Alpha-Beta Pruning in adversarial search?", answer: "A massive mechanical optimization for Minimax. By keeping tracking of the absolute best option guaranteed so far for Max ('Alpha') and Min ('Beta'), the algorithm can mathematically prove when a certain branch of the game tree is completely pointless to explore. If the Opponent has a move that kills you instantly, you don't need to explore the other 34 moves branching off that path—you cut off (prune) the entire branch, doubling the depth the AI can computationally search in the same timeframe." },
    { question: "Explain Monte Carlo Tree Search (MCTS) and why it replaced Minimax in the game of Go.", answer: "The branching factor in 'Go' is ~250. Minimax with Alpha-Beta instantly crashes computing limits. MCTS abandons evaluating every move. Instead, from a current board state, it rapidly plays out thousands of completely <strong>randomized, simulated games</strong> to the very end (Playouts/Rollouts). It mathematically builds statistics on which opening moves led to the highest percentage of random victories. AlphaGo used MCTS alongside Neural Networks to crush human champions." },
    { question: "What is a Heuristic Evaluation Function in board games?", answer: "Because Minimax usually cannot reach the absolute end of a Chess game, it stops at a certain depth (e.g., 8 turns ahead). Since the game isn't over, you don't have a Win/Loss score. A Heuristic Evaluation Function is a static mathematical formula evaluating how 'good' the board looks right now. (e.g., +9 points for Queen, +1 point for Pawn, + positional modifiers). Minimax runs its math based on these mid-game fuzzy scores." },
    { question: "What is the 'Horizon Effect' in AI Game Search?", answer: "A fatal flaw in depth-limited Minimax. If an AI can only see 8 moves ahead, it might see a sequence where it saves its Queen. It thinks it is brilliant. But on the 9th move (just past its 'horizon'), it gets checkmated. It makes terrible early decisions to maliciously push inevitable defeat exactly one move out of its visual range. Solved via 'Quiescence Search' (refusing to stop evaluating if chaotic captures are occurring)." },
    { question: "Explain Genetic Algorithms in the context of Search/Optimization.", answer: "Inspired by Darwinian evolution. Instead of searching a mathematical grid, it randomly generates 100 flawed solutions (A Population). It tests them all. It kills the 50 worst. It takes the 50 best, randomly mixes their variables together ('Crossover'), mutates a tiny random percentage of values to maintain diversity, and tests the massive new generation. Valid for insanely complex problems (like drone wing aerodynamics) where calculating distinct gradients is impossible." },
    { question: "What is Simulated Annealing?", answer: "An optimization algorithm inspired by metallurgy (heating and slowly cooling metal to strengthen it). It tries to find the Global Minimum in a chaotic landscape. Early on (when 'Hot'), the algorithm will intentionally and frequently accept terrible, wrong moves, wildly jumping out of small local valleys. As time passes, it slowly 'cools' down, refusing chaotic jumps, rigidly locking into and optimizing whatever deep valley it eventually landed in." },
    { question: "Compare Gradient Descent to traditional Search Algorithms.", answer: "A search algorithm like A* looks at every possible discrete pathway on a grid to find an answer. Gradient Descent is used in continuous calculus space. Instead of searching a map, it looks at the mathematical slope of the error at its exact current location, and blindly takes a tiny step precisely 'downhill'. It searches entirely via mathematical derivatives rather than expanding geometric nodes." },
    { question: "What is Hill Climbing Search, and what is its absolute worst flaw?", answer: "A greedy local search algorithm. It looks at all adjacent neighbors and moves to the one strictly higher than its current position. It stops instantly when all neighbors are lower. \n<strong>Flaw:</strong> It gets violently stuck on 'Local Maxima'. If it climbs a small hill next to Everest, it stops at the small hill's peak because moving towards Everest initially requires descending. It has zero capacity to look past its immediate neighbors." },
    { question: "What is the Traveling Salesman Problem (TSP), and why do we use Heuristics to solve it?", answer: "Finding the shortest possible route that visits every city exactly once and returns home. It is an NP-Hard combinatorial problem. For 5 cities, it's 120 paths. For 20 cities, it is 2.4 Quintillion paths. A perfect A* search will crash. We must use heuristic/approximate search algorithms (like Simulated Annealing or Genetic Algorithms) that guarantee a 'really good, 98% efficient route in 2 seconds' rather than 'the perfect route in 1,000 years'." },
    { question: "What is Iterative Deepening Depth-First Search (IDDFS)?", answer: "A hybrid that combines the best parts of BFS (guarantees shortest path) and DFS (uses extremely low memory). It runs a DFS with a hard depth limit of 1. Then it wipes the board and runs a DFS with a limit of 2. Then 3. And so on. Although it 're-runs' the top of the tree repeatedly, the exponential growth at the bottom of the tree makes the overhead mathematically trivial, yielding an incredible low-memory optimal pathfinder." },
    { question: "What is the mathematical 'Branching Factor', and how does it dictate algorithm selection?", answer: "The average number of valid moves available from any given state. Chess is ~35. Go is ~250. Rubik's Cube is ~13. A small branching factor allows deep Minimax or A* trees. An immense branching factor forces you to abandon rigid expansion entirely and rely on aggressive neural-network heuristics, heavy pruning, or Monte Carlo randomized playouts." }
];

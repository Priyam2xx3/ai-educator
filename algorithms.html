<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithms & Metrics | AI Educator</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="app-container">
        <!-- Navbar -->
        <nav class="navbar">
            <div class="logo">‚ú¶ AI<span>Educator</span></div>
            <div class="nav-actions">
                <a href="index.html" class="nav-link">Home</a>
                <a href="roadmap.html" class="btn btn-outline" style="padding: 0.5rem 1rem;">Roadmap</a>
                <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">üåô</button>
                <button id="mobile-menu-btn" class="mobile-menu-btn">‚ò∞</button>
            </div>
        </nav>

        <!-- Main Layout -->
        <div class="main-content-layout">
            <!-- Sidebar -->
            <aside id="sidebar" class="sidebar">
                <div class="nav-links">
                    <a href="index.html">üè† Home</a>
                    <a href="roadmap.html">üìç Roadmap</a>
                    <a href="ml.html">üìò Machine Learning</a>
                    <a href="dl.html">üìó Deep Learning</a>
                    <a href="transformers.html">üìï Transformers</a>
                    <a href="llm.html">üìô LLMs</a>
                    <a href="rag.html">üìí RAG</a>
                    <a href="agents.html">üìì AI Agents</a>
                    <a href="algorithms.html" class="active">üìë Algorithms</a>
                    <a href="references.html">üìé References</a>
                </div>
            </aside>

            <!-- Page Content -->
            <main class="content-area">
                <h1 class="page-header delay-1">Algorithms, Optimizers & Metrics</h1>

                <section class="glass delay-1" style="padding: 2rem; margin-bottom: 2rem;">
                    <h2>The Math Behind the Magic</h2>
                    <p>Models learn by minimizing their errors. To do this, they need a way to measure the error (Loss
                        Function) and a way to update their internal weights to reduce that error (Optimizer). Finally,
                        we need Metrics to evaluate the true success of the model.</p>
                </section>

                <div class="accordion delay-2">
                    <div class="accordion-item">
                        <div class="accordion-header">
                            Loss Functions
                            <span class="accordion-icon">‚ñº</span>
                        </div>
                        <div class="accordion-content">
                            <ul style="margin-top: 1rem;">
                                <li><strong>What is it?</strong> A mathematical way of measuring how far off the model's
                                    predictions are from the true labels. The goal of training is to minimize this
                                    value.</li>
                                <li><strong>Mean Squared Error (MSE):</strong> Used for Regression tasks (predicting
                                    numbers). Measures the average squared difference between estimated values and the
                                    actual value.</li>
                                <li><strong>Cross-Entropy Loss:</strong> Used for Classification tasks (predicting
                                    categories). It heavily penalizes confident but incorrect predictions using
                                    logarithmic formulas.</li>
                            </ul>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <div class="accordion-header">
                            Optimizers
                            <span class="accordion-icon">‚ñº</span>
                        </div>
                        <div class="accordion-content">
                            <ul style="margin-top: 1rem;">
                                <li><strong>Gradient Descent:</strong> The foundational optimization algorithm. It
                                    calculates the gradient (slope) of the loss function with respect to the weights,
                                    and takes a "step" downwards against the gradient.</li>
                                <li><strong>Stochastic Gradient Descent (SGD):</strong> Instead of calculating the
                                    gradient over the entire dataset (which is slow), it calculates it over small random
                                    batches. Fast, but the path to the minimum is noisy.</li>
                                <li><strong>Adam (Adaptive Moment Estimation):</strong> The most popular optimizer
                                    today. It combining the advantages of AdaGrad and RMSProp by computing individual
                                    adaptive learning rates for different parameters from estimates of first and second
                                    moments of the gradients.</li>
                            </ul>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <div class="accordion-header">
                            Evaluation Metrics
                            <span class="accordion-icon">‚ñº</span>
                        </div>
                        <div class="accordion-content">
                            <ul style="margin-top: 1rem;">
                                <li><strong>Accuracy:</strong> Total correct predictions divided by total predictions.
                                    Only useful when classes are perfectly balanced.</li>
                                <li><strong>Precision:</strong> "Out of all the emails the model flagged as SPAM, how
                                    many were actually SPAM?" True Positives / (True Positives + False Positives).
                                    Crucial when False Positives are costly.</li>
                                <li><strong>Recall (Sensitivity):</strong> "Out of all the actual SPAM emails, how many
                                    did the model successfully find?" True Positives / (True Positives + False
                                    Negatives). Crucial for medical tests where False Negatives can be fatal.</li>
                                <li><strong>F1-Score:</strong> The harmonic mean of Precision and Recall. best metric if
                                    there is an uneven class distribution.</li>
                            </ul>
                            <div
                                style="background: var(--card-border); padding: 2rem; margin: 1.5rem 0; border-radius: 0.5rem; color: var(--text-muted); font-family: monospace;">
                                Predicted Positive | Predicted Negative<br>
                                Actual Positive: True Positive! | False Negative (Type II)<br>
                                Actual Negative: False Positive | True Negative!
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <div class="accordion-header">
                            Deep Dive Q&A (A Curious Student's Treasure)
                            <span class="accordion-icon">‚ñº</span>
                        </div>
                        <div class="accordion-content">
                            <ul style="margin-top: 1rem;">
                                <li>
                                    <strong>Q: Why do we use Cross-Entropy for Classification instead of Mean Squared
                                        Error (MSE)?</strong><br>
                                    <span class="text-muted">A: MSE expects continuous numbers (like predicting a house
                                        price of $300,500). In classification, outcomes are probabilities of distinct
                                        categories (e.g., 90% Dog, 10% Cat). Cross-Entropy uses logarithms to heavily
                                        penalize the model when it is confidently wrong. If the model says "99% Cat" but
                                        it's actually a Dog, Cross-Entropy causes the error (Loss) to explode towards
                                        infinity, creating a massive, corrective gradient update that MSE could never
                                        achieve.</span>
                                </li>
                                <li style="margin-top: 1rem;">
                                    <strong>Q: What is the "Learning Rate" and why is it so hard to tune?</strong><br>
                                    <span class="text-muted">A: Imagine walking blindly down a mountain to find the
                                        lowest valley. The Learning Rate is the size of your steps. If the step is too
                                        big, you'll constantly overshoot the valley and bounce up the other side
                                        (divergence). If the step is too small, it will take you a million tiny
                                        shuffling steps to reach the bottom (slow training). Finding the perfect step
                                        size is a delicate art.</span>
                                </li>
                                <li style="margin-top: 1rem;">
                                    <strong>Q: Why does the Adam Optimizer sometimes fail to generalize well compared to
                                        SGD?</strong><br>
                                    <span class="text-muted">A: Adam mathematically adapts its step size for every
                                        individual parameter, meaning it aggressively sprints straight down into the
                                        nearest, sharpest valley in the loss landscape. While fast, sharp valleys often
                                        mean the model memorized the training data and will perform poorly on new data.
                                        SGD (Stochastic Gradient Descent) uses a fixed step size and inherently has
                                        "noise" (randomness) in its direction. This noise often bumps it out of sharp
                                        valleys and pushes it into broad, flat valleys, which mathematically represents
                                        finding universally true, generalizing patterns!</span>
                                </li>
                                <li style="margin-top: 1rem;">
                                    <strong>Q: Explain the difference between Precision and Recall. When does one matter
                                        more?</strong><br>
                                    <span class="text-muted">A: <strong>Precision</strong> prevents False Positives
                                        ("Out of all the people I arrested, how many were actually guilty?").
                                        <strong>Recall</strong> prevents False Negatives ("Out of all the guilty people
                                        in the city, how many did I catch?").<br>We optimize for
                                        <strong>Precision</strong> in YouTube recommendations (If we recommend a bad
                                        video, the user leaves. A false positive is terrible).<br>We optimize for
                                        <strong>Recall</strong> in Cancer Screening (If we miss a tumor, the patient
                                        dies. A false negative is fatal. It's better to flag a benign spot for further
                                        testing).</span>
                                </li>
                                <li style="margin-top: 1rem;">
                                    <strong>Q: What is the F1-Score, and why use it instead of overall
                                        Accuracy?</strong><br>
                                    <span class="text-muted">A: Overall Accuracy fails spectacularly on unbalanced data.
                                        If a factory produces 99 good parts and 1 broken part, a model that simply
                                        always says "Good Part" is 99% accurate, but completely useless at its job! The
                                        F1-Score combines Precision and Recall mathematically (their harmonic mean) into
                                        a single number that severely punishes the model if it completely ignores one of
                                        the classes, ensuring true balanced performance.</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>

            </main>
        </div>

        <button id="backToTop" title="Go to top">‚Üë</button>
    </div>

    <script src="script.js"></script>
</body>

</html>